services:
  postgres:
    image: postgres:15
    container_name: postgres
    restart: always
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: admin
      POSTGRES_DB: educacionit
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data

  hadoop-namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-namenode
    environment:
      - CLUSTER_NAME=test
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode:8020
    ports:
      - "9870:9870"
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
    depends_on:
      - postgres

  hadoop-datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-datanode
    environment:
      - SERVICE_PRECONDITION=hadoop-namenode:9870
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode:8020
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
    depends_on:
      - hadoop-namenode

  spark-master:
    image: bde2020/spark-master:3.1.1-hadoop3.2
    container_name: spark-master
    ports:
      - "7077:7077"
      - "8080:8080"
    environment:
      - INIT_DAEMON_STEP=setup_spark

  spark-worker:
    image: bde2020/spark-worker:3.1.1-hadoop3.2
    container_name: spark-worker
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    ports:
      - "8081:8081"

  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-server
    depends_on:
      - hadoop-namenode
      - hadoop-datanode
      - postgres
    ports:
      - "10000:10000"
      - "10002:10002"
    environment:
      HIVE_METASTORE_DB_TYPE: postgres
      HIVE_DB: metastore
      HIVE_DB_USERNAME: admin
      HIVE_DB_PASSWORD: admin
      HIVE_JDBC_URL: jdbc:postgresql://postgres:5432/educacionit
    ulimits:
      nofile:
        soft: 65536
        hard: 65536

  jupyter:
    image: jupyter/pyspark-notebook:latest
    container_name: jupyter
    restart: always
    ports:
      - "8888:8888"
      - "4040:4040"
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - SPARK_OPTS=--driver-java-options=-Xms1024M --driver-java-options=-Xmx4096M --driver-java-options=-Dlog4j.log4j.configuration=file:/usr/local/spark/conf/log4j.properties
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./Etapa 1:/home/jovyan/work/data
    depends_on:
      - postgres
      - spark-master
      - spark-worker
    command: start.sh jupyter lab --LabApp.token='' --LabApp.password='' --ip=0.0.0.0 --port=8888 --allow-root --no-browser

volumes:
  pgdata:
  hadoop_namenode:
  hadoop_datanode:
