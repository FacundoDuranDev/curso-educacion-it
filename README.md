# ClÃºster Hadoop-Hive-Spark con Jupyter Notebook en Docker

## ğŸš¨ **IMPORTANTE: Diferencia en Nombres de Contenedores**

**Docker Compose v2 (actual - guiones medios):**
- `educacionit-metastore-1`
- `educacionit-master-1` 
- `educacionit-worker1-1`

**Docker Compose v1 (anterior - guiones bajos):**
- `educacionit_metastore_1`
- `educacionit_master_1` 
- `educacionit_worker1_1`

**ğŸ” Verificar tu versiÃ³n:**
```bash
docker-compose --version
```

**ğŸ’¡ Tip**: Siempre usa `docker-compose ps` para ver los nombres exactos.

**ğŸ”§ Script de DetecciÃ³n AutomÃ¡tica:**
```bash
./detect_container_names.sh
```
Este script detecta automÃ¡ticamente tu versiÃ³n de Docker Compose y muestra los nombres correctos.

## âš ï¸ ADVERTENCIA DE SEGURIDAD
**Este clÃºster estÃ¡ diseÃ±ado exclusivamente para entornos de desarrollo, pruebas y aprendizaje. NO utilizar en entornos de producciÃ³n.**

---

## ğŸ“‹ REQUISITOS DEL SISTEMA

### Dependencias de Software
- Docker Engine 20.10+
- Docker Compose 2.0+
- MÃ­nimo 8GB RAM disponible
- Puertos TCP disponibles: 8088, 9870, 10000, 8888, 18080, 19888

### Especificaciones TÃ©cnicas
- **Sistema Operativo**: Linux (recomendado), macOS, Windows con WSL2
- **Arquitectura**: x86_64
- **Almacenamiento**: MÃ­nimo 20GB de espacio libre en disco

---

## ğŸš€ DESPLIEGUE DEL CLÃšSTER

### Fase 1: ConstrucciÃ³n de ImÃ¡genes Docker
```bash
make
```

**Nota:** El comando `make` ejecuta automÃ¡ticamente `make build` seguido de `make up`, construyendo todas las imÃ¡genes y levantando el entorno completo.

**DescripciÃ³n TÃ©cnica**: Este comando ejecuta el Makefile que construye secuencialmente las imÃ¡genes Docker base, master, worker, history y jupyter utilizando los Dockerfiles correspondientes en cada directorio.

### Fase 2: InicializaciÃ³n del ClÃºster
```bash
docker-compose up -d
```

**DescripciÃ³n TÃ©cnica**: Levanta todos los servicios definidos en docker-compose.yml en modo detached, creando la red personalizada `sparknet` (172.28.0.0/16) y estableciendo las dependencias entre servicios.

### Fase 3: VerificaciÃ³n del Estado del ClÃºster
```bash
make status
```

**DescripciÃ³n TÃ©cnica**: Verifica el estado operativo de todos los contenedores del clÃºster. La salida esperada debe mostrar todos los servicios en estado `running`.

**Salida Esperada**:
```
NAME                    COMMAND                  SERVICE             STATUS              PORTS
hadoop-hive-spark-â€¦    "/opt/hadoop/bin/entâ€¦"   master             running             0.0.0.0:8088->8088/tcp
hadoop-hive-spark-â€¦    "/opt/hadoop/bin/entâ€¦"   worker1            running             0.0.0.0:8042->8042/tcp
hadoop-hive-spark-â€¦    "/opt/hadoop/bin/entâ€¦"   worker2            running             0.0.0.0:8043->8042/tcp
```

---

## ğŸ“š **GUÃAS DISPONIBLES**

### **Para Estudiantes:**
- ğŸš€ **`GUIA_INSTALACION_RAPIDA.md`** - InstalaciÃ³n rÃ¡pida del entorno
- ğŸ—„ï¸ **`GUIA_INSTALACION_POSTGRESQL.md`** - ConfiguraciÃ³n completa de PostgreSQL con datos
- ğŸ”Œ **`GUIA_DBEAVER_POSTGRESQL_WINDOWS.md`** - ConexiÃ³n con DBeaver desde Windows
- ğŸ“Š **`GUIA_SQL.md`** - GuÃ­a bÃ¡sica de sintaxis SQL
- ğŸ—ï¸ **`EJEMPLOS_NORMALIZACION.md`** - Ejemplos de normalizaciÃ³n de bases de datos

### **Para Desarrolladores:**
- ğŸ³ **`COMANDOS_RAPIDOS_DOCKER.md`** - Comandos Docker Ãºtiles
- ğŸ§ **`COMANDOS_BASICOS_LINUX.md`** - Comandos Linux bÃ¡sicos
- ğŸ§¹ **`CLEANUP.md`** - Limpieza y mantenimiento del entorno

---

## ğŸ”§ CONFIGURACIÃ“N DE HDFS PARA HIVE

### Contexto TÃ©cnico
HDFS (Hadoop Distributed File System) requiere la creaciÃ³n de directorios especÃ­ficos para el funcionamiento correcto de Apache Hive. Estos directorios deben existir antes de iniciar los servicios de Hive.

### Paso 2.1: Acceso al Contenedor Master
```bash
docker exec -it master bash
```

**ParÃ¡metros del Comando**:
- `exec`: Ejecuta un comando en un contenedor en ejecuciÃ³n
- `-i`: Modo interactivo (mantiene STDIN abierto)
- `-t`: Asigna una pseudo-TTY
- `master`: Nombre del contenedor objetivo
- `bash`: Shell a ejecutar

**Indicador de Ã‰xito**: El prompt cambiarÃ¡ a `root@master:/opt/hadoop#`

### Paso 2.2: CreaciÃ³n de Directorios HDFS
```bash
# Directorio principal del warehouse de Hive
hdfs dfs -mkdir -p /user/hive/warehouse

# Directorio temporal para operaciones
hdfs dfs -mkdir -p /tmp

# Directorio de usuario de Hive
hdfs dfs -mkdir -p /user/hive
```

**Comandos HDFS Utilizados**:
- `hdfs dfs -mkdir -p`: Crea directorios en HDFS con opciÃ³n recursiva
- `-p`: Crea directorios padre si no existen

### Paso 2.3: ConfiguraciÃ³n de Permisos HDFS
```bash
# Asignar permisos de lectura, escritura y ejecuciÃ³n para todos los usuarios
hdfs dfs -chmod 777 /user/hive/warehouse
hdfs dfs -chmod 777 /tmp
hdfs dfs -chmod 777 /user/hive
```

**EspecificaciÃ³n de Permisos 777**:
- Primer 7: Propietario (rwx = 4+2+1)
- Segundo 7: Grupo (rwx = 4+2+1)  
- Tercer 7: Otros (rwx = 4+2+1)

**Nota de Seguridad**: Los permisos 777 se utilizan Ãºnicamente en entornos de desarrollo.

### Paso 2.4: VerificaciÃ³n de CreaciÃ³n de Directorios
```bash
# Listar contenido del directorio warehouse
hdfs dfs -ls /user/hive/

# Listar contenido del directorio temporal
hdfs dfs -ls /tmp/
```

**Salida Esperada**: `drwxrwxrwx` seguido de los nombres de directorios, indicando permisos 777.

### Paso 2.5: TerminaciÃ³n de SesiÃ³n
```bash
exit
```

---

## ğŸ CONFIGURACIÃ“N DE APACHE HIVE

### Contexto TÃ©cnico
Apache Hive requiere una configuraciÃ³n especÃ­fica del archivo `hive-site.xml` para funcionar correctamente con PostgreSQL como metastore y HDFS como almacenamiento.

### Paso 3.1: Reacceso al Contenedor Master
```bash
docker exec -it master bash
```

### Paso 3.2: Backup de ConfiguraciÃ³n Actual
```bash
# Crear respaldo de la configuraciÃ³n existente
cp /opt/hive/conf/hive-site.xml /opt/hive/conf/hive-site.xml.backup
```

**PropÃ³sito**: Mantener una copia de seguridad de la configuraciÃ³n original para recuperaciÃ³n en caso de fallos.

### Paso 3.3: AplicaciÃ³n de ConfiguraciÃ³n Optimizada
```bash
# Aplicar configuraciÃ³n pre-validada
cp /opt/hive/conf/hive-site-working.xml /opt/hive/conf/hive-site.xml
```

**DescripciÃ³n TÃ©cnica**: El archivo `hive-site-working.xml` contiene la configuraciÃ³n optimizada que incluye:
- ConfiguraciÃ³n del metastore PostgreSQL
- ParÃ¡metros de HiveServer2
- ConfiguraciÃ³n de HDFS
- ParÃ¡metros de ejecuciÃ³n

### Paso 3.4: Reinicio de Servicios de Hive
```bash
# TerminaciÃ³n de procesos Hive existentes
pkill -f HiveServer2
pkill -f MetaStore

# InicializaciÃ³n del servicio metastore en background
/opt/hive/bin/hive --service metastore &

# InicializaciÃ³n del servicio HiveServer2 en background
/opt/hive/bin/hive --service hiveserver2 &
```

**Comandos de Proceso**:
- `pkill -f`: Termina procesos basÃ¡ndose en coincidencia de patrones
- `&`: Ejecuta el comando en background

**Servicios Iniciados**:
- **Metastore**: Gestiona metadatos de tablas y particiones
- **HiveServer2**: Proporciona interfaz JDBC/ODBC para conexiones

### Paso 3.5: TerminaciÃ³n de SesiÃ³n
```bash
exit
```

---

## âœ… VERIFICACIÃ“N DE FUNCIONALIDAD

### Paso 4.1: VerificaciÃ³n de Estado de HiveServer2
```bash
# Verificar que HiveServer2 estÃ© escuchando en el puerto 10000
docker exec master netstat -tlnp | grep 10000
```

**Salida Esperada**: `tcp 0 0 0.0.0.0:10000 0.0.0.0:* LISTEN`

**InterpretaciÃ³n**: El servicio HiveServer2 estÃ¡ activo y escuchando conexiones en todas las interfaces del puerto 10000.

### Paso 4.2: ConexiÃ³n de Prueba a Hive
```bash
# Establecer conexiÃ³n JDBC a Hive mediante beeline
docker exec -it master /opt/hive/bin/beeline -u jdbc:hive2://localhost:10000
```

**Componentes TÃ©cnicos**:
- **Beeline**: Cliente de lÃ­nea de comandos para Hive basado en SQLLine
- **JDBC URL**: `jdbc:hive2://localhost:10000` - ConexiÃ³n local al puerto 10000

**Indicadores de ConexiÃ³n Exitosa**:
- Mensaje de versiÃ³n: `Beeline version 3.1.3 by Apache Hive`
- Prompt de conexiÃ³n: `0: jdbc:hive2://localhost:10000>`

### Paso 4.3: Prueba de Funcionalidad
```sql
-- Consulta de verificaciÃ³n de bases de datos
SHOW DATABASES;
```

**PropÃ³sito**: Verificar que Hive responda correctamente a consultas SQL bÃ¡sicas.

### Paso 4.4: TerminaciÃ³n de SesiÃ³n Beeline
```sql
!quit
```

---

## ğŸŒ INTERFACES DE ADMINISTRACIÃ“N WEB

### Hadoop Distributed File System (HDFS)
- **NameNode Web UI**: http://localhost:9870 - AdministraciÃ³n de metadatos HDFS
- **ResourceManager Web UI**: http://localhost:8088 - GestiÃ³n de recursos YARN
- **HistoryServer Web UI**: http://localhost:19888 - Historial de trabajos MapReduce

### Apache Spark
- **Spark Master Web UI**: http://localhost:8080 - Estado del clÃºster Spark
- **Worker1 Web UI**: http://localhost:8081 - Estado del worker 1
- **Worker2 Web UI**: http://localhost:8082 - Estado del worker 2
- **Spark History Server**: http://localhost:18080 - Historial de aplicaciones Spark

### Apache Hive
- **JDBC Connection String**: `jdbc:hive2://localhost:10000`
- **Protocolo**: HiveServer2 Thrift

### Jupyter Notebook
- **Web Interface**: http://localhost:8888
- **Kernel Disponible**: PySpark
- **Ejemplo de Notebook**: [jupyter/notebook/pyspark.ipynb](jupyter/notebook/pyspark.ipynb)

---

## ğŸ› ï¸ GESTIÃ“N OPERATIVA DEL CLÃšSTER

### Monitoreo del Estado
```bash
# Estado de todos los contenedores
docker-compose ps

# Logs de todos los servicios
docker-compose logs

# Logs en tiempo real de servicios especÃ­ficos
docker-compose logs -f master
docker-compose logs -f metastore
```

### Control de Servicios
```bash
# Detener todos los servicios
make down

# Iniciar todos los servicios
make up

# Verificar estado del clÃºster
make status

# Limpieza de imÃ¡genes Docker
make clean
```

---

## ğŸ” RESOLUCIÃ“N DE PROBLEMAS

### Problema: Fallo de ConexiÃ³n a Hive
**SÃ­ntomas**: Error de conexiÃ³n JDBC o timeout en beeline

**Procedimiento de DiagnÃ³stico**:
1. **VerificaciÃ³n de PostgreSQL**:
   ```bash
   docker-compose logs metastore
   ```

2. **VerificaciÃ³n de Directorios HDFS**:
   ```bash
   docker exec master hdfs dfs -ls /user/hive/
   ```

3. **VerificaciÃ³n de ConfiguraciÃ³n Hive**:
   ```bash
   docker exec master ls -la /opt/hive/conf/hive-site.xml
   ```

4. **VerificaciÃ³n de Estado de HiveServer2**:
   ```bash
   docker exec master netstat -tlnp | grep 10000
   ```

### Problema: HDFS No Accesible
**SÃ­ntomas**: Errores de permisos o directorios no encontrados

**Procedimiento de DiagnÃ³stico**:
1. **VerificaciÃ³n de NameNode**:
   ```bash
   docker-compose logs master
   ```

2. **VerificaciÃ³n de DataNodes**:
   - Acceder a http://localhost:9870
   - Verificar que 2 DataNodes estÃ©n en estado "Active"

### Problema: Spark No Operativo
**SÃ­ntomas**: Interfaz web no accesible o workers desconectados

**Procedimiento de DiagnÃ³stico**:
1. **VerificaciÃ³n de Spark Master**:
   - Acceder a http://localhost:8080
   - Verificar estado del master

2. **VerificaciÃ³n de Workers**:
   - En http://localhost:8080 verificar presencia de 2 workers
   - Estado de workers debe ser "ALIVE"

---

## ğŸ“š STACK TECNOLÃ“GICO

### Componentes Core
- **Apache Hadoop 3.3.6**: Framework de procesamiento distribuido
- **Apache Hive 3.1.3**: Data warehouse para consultas SQL
- **Apache Spark 3.5.3**: Motor de procesamiento de datos en memoria
- **PostgreSQL 11**: Sistema de gestiÃ³n de bases de datos relacional
- **Jupyter Notebook**: Entorno de desarrollo interactivo

### Versiones de Componentes
- **Java**: OpenJDK 8
- **Python**: Python 3.8+
- **Scala**: Scala 2.12

---

## ğŸ—ï¸ ARQUITECTURA DEL CLÃšSTER

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Metastore â”‚    â”‚    Master   â”‚    â”‚   Worker1   â”‚
â”‚ (PostgreSQL)â”‚    â”‚ (NameNode,  â”‚    â”‚ (DataNode,  â”‚
â”‚             â”‚    â”‚ ResourceMgr)â”‚    â”‚  NodeMgr)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚                   â”‚
       â”‚                   â”‚                   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚       â”‚       â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚Worker2  â”‚ â”‚ History â”‚
              â”‚(DataNodeâ”‚ â”‚(History â”‚
              â”‚ NodeMgr)â”‚ â”‚ Server) â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### DescripciÃ³n de Componentes
- **Metastore (PostgreSQL)**: Almacena metadatos de tablas, particiones y esquemas de Hive
- **Master Node**: Coordina el clÃºster (NameNode + ResourceManager)
- **Worker Nodes**: Procesan datos y almacenan bloques HDFS
- **History Server**: Mantiene historial de trabajos Spark y MapReduce

---

## ğŸš€ PROCEDIMIENTO DE CONFIGURACIÃ“N COMPLETO

### ConfiguraciÃ³n Manual (Recomendado para Entornos de Desarrollo)
```bash
# 1. Despliegue del clÃºster
make
docker-compose up -d

# 2. Acceso al contenedor master
docker exec -it master bash

# 3. ConfiguraciÃ³n de HDFS
hdfs dfs -mkdir -p /user/hive/warehouse /tmp /user/hive
hdfs dfs -chmod 777 /user/hive/warehouse /tmp /user/hive

# 4. ConfiguraciÃ³n de Hive
cp /opt/hive/conf/hive-site-working.xml /opt/hive/conf/hive-site.xml

# 5. Reinicio de servicios Hive
pkill -f HiveServer2 && pkill -f MetaStore
/opt/hive/bin/hive --service metastore &
/opt/hive/bin/hive --service hiveserver2 &

# 6. TerminaciÃ³n de sesiÃ³n
exit

# 7. VerificaciÃ³n de funcionalidad
docker exec master netstat -tlnp | grep 10000
```

### ConfiguraciÃ³n Automatizada (Para Entornos de ProducciÃ³n/Testing)
```bash
# Despliegue y configuraciÃ³n completa en una secuencia
make && docker-compose up -d
docker exec master hdfs dfs -mkdir -p /user/hive/warehouse /tmp /user/hive
docker exec master hdfs dfs -chmod 777 /user/hive/warehouse /tmp /user/hive
docker exec master cp /opt/hive/conf/hive-site-working.xml /opt/hive/conf/hive-site.xml
docker exec master bash -c "pkill -f HiveServer2; pkill -f MetaStore; /opt/hive/bin/hive --service metastore & /opt/hive/bin/hive --service hiveserver2 &"
```

---

## ğŸ“ CONSIDERACIONES TÃ‰CNICAS

### ConfiguraciÃ³n de Red
- **Subnet**: 172.28.0.0/16
- **IPs EstÃ¡ticas**: Asignadas a cada servicio para comunicaciÃ³n interna
- **Port Mapping**: Mapeo de puertos internos a puertos del host

### Persistencia de Datos
- **VolÃºmenes Docker**: Mantienen datos entre reinicios del clÃºster
- **HDFS**: Almacenamiento distribuido con replicaciÃ³n
- **PostgreSQL**: Metadatos persistentes de Hive

### ConfiguraciÃ³n de Seguridad
- **AutenticaciÃ³n**: Configurada como NONE para desarrollo
- **Permisos HDFS**: 777 para facilitar operaciones de desarrollo
- **Red Aislada**: ComunicaciÃ³n interna a travÃ©s de red Docker personalizada

---

## ğŸ¯ OPERACIONES POST-CONFIGURACIÃ“N

### VerificaciÃ³n de Funcionalidad
1. **HDFS**: Acceder a http://localhost:9870 para explorar el sistema de archivos
2. **Hive**: Conectar via beeline y ejecutar consultas SQL de prueba
3. **Spark**: Verificar estado en http://localhost:8080
4. **Jupyter**: Desarrollar notebooks PySpark en http://localhost:8888

### Monitoreo Continuo
- **Logs de Servicios**: `docker-compose logs -f [servicio]`
- **Estado de Contenedores**: `docker-compose ps`
- **MÃ©tricas HDFS**: http://localhost:9870
- **MÃ©tricas YARN**: http://localhost:8088

---

## ğŸ†˜ SOPORTE TÃ‰CNICO

### Procedimiento de ResoluciÃ³n de Problemas
1. **AnÃ¡lisis de Logs**: `docker-compose logs -f [servicio_afectado]`
2. **VerificaciÃ³n de Estado**: `docker-compose ps`
3. **DocumentaciÃ³n**: Revisar este README para procedimientos especÃ­ficos
4. **ReinicializaciÃ³n**: `make clean && make && docker-compose up -d`

### Recursos de DiagnÃ³stico
- **Docker Logs**: InformaciÃ³n detallada de servicios
- **Interfaces Web**: Monitoreo en tiempo real
- **Comandos de VerificaciÃ³n**: Scripts de diagnÃ³stico incluidos

**Nota**: La primera inicializaciÃ³n puede requerir tiempo adicional para descarga de imÃ¡genes y configuraciÃ³n inicial.