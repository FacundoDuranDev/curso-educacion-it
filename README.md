# Cl√∫ster Hadoop-Hive-Spark con Jupyter Notebook en Docker

## üö® **IMPORTANTE: Diferencia en Nombres de Contenedores**

**Docker Compose v2 (actual - guiones medios):**
- `educacionit-metastore-1`
- `educacionit-master-1` 
- `educacionit-worker1-1`

**Docker Compose v1 (anterior - guiones bajos):**
- `educacionit_metastore_1`
- `educacionit_master_1` 
- `educacionit_worker1_1`

**üîç Verificar tu versi√≥n:**
```bash
docker-compose --version
```

**üí° Tip**: Siempre usa `docker-compose ps` para ver los nombres exactos.

**üîß Script de Detecci√≥n Autom√°tica:**
```bash
./detect_container_names.sh
```
Este script detecta autom√°ticamente tu versi√≥n de Docker Compose y muestra los nombres correctos.

## ‚ö†Ô∏è ADVERTENCIA DE SEGURIDAD
**Este cl√∫ster est√° dise√±ado exclusivamente para entornos de desarrollo, pruebas y aprendizaje. NO utilizar en entornos de producci√≥n.**

---

## üìã REQUISITOS DEL SISTEMA

### Dependencias de Software
- Docker Engine 20.10+
- Docker Compose 2.0+
- M√≠nimo 8GB RAM disponible
- Puertos TCP disponibles: 8088, 9870, 10000, 8888, 18080, 19888

### Especificaciones T√©cnicas
- **Sistema Operativo**: Linux (recomendado), macOS, Windows con WSL2
- **Arquitectura**: x86_64
- **Almacenamiento**: M√≠nimo 20GB de espacio libre en disco

---

## üöÄ DESPLIEGUE DEL CL√öSTER

### Fase 1: Construcci√≥n de Im√°genes Docker
```bash
make
```

**Nota:** El comando `make` ejecuta autom√°ticamente `make build` seguido de `make up`, construyendo todas las im√°genes y levantando el entorno completo.

**Descripci√≥n T√©cnica**: Este comando ejecuta el Makefile que construye secuencialmente las im√°genes Docker base, master, worker, history y jupyter utilizando los Dockerfiles correspondientes en cada directorio.

### Fase 2: Inicializaci√≥n del Cl√∫ster
```bash
docker-compose up -d
```

**Descripci√≥n T√©cnica**: Levanta todos los servicios definidos en docker-compose.yml en modo detached, creando la red personalizada `sparknet` (172.28.0.0/16) y estableciendo las dependencias entre servicios.

### Fase 3: Verificaci√≥n del Estado del Cl√∫ster
```bash
make status
```

**Descripci√≥n T√©cnica**: Verifica el estado operativo de todos los contenedores del cl√∫ster. La salida esperada debe mostrar todos los servicios en estado `running`.

**Salida Esperada**:
```
NAME                    COMMAND                  SERVICE             STATUS              PORTS
hadoop-hive-spark-‚Ä¶    "/opt/hadoop/bin/ent‚Ä¶"   master             running             0.0.0.0:8088->8088/tcp
hadoop-hive-spark-‚Ä¶    "/opt/hadoop/bin/ent‚Ä¶"   worker1            running             0.0.0.0:8042->8042/tcp
hadoop-hive-spark-‚Ä¶    "/opt/hadoop/bin/ent‚Ä¶"   worker2            running             0.0.0.0:8043->8042/tcp
```

---

## üìö **GU√çAS DISPONIBLES**

### **Para Estudiantes:**
- üöÄ **`GUIA_INSTALACION_RAPIDA.md`** - Instalaci√≥n r√°pida del entorno
- üóÑÔ∏è **`GUIA_INSTALACION_POSTGRESQL.md`** - Configuraci√≥n completa de PostgreSQL con datos
- üîå **`GUIA_DBEAVER_POSTGRESQL_WINDOWS.md`** - Conexi√≥n con DBeaver desde Windows
- üìä **`GUIA_SQL.md`** - Gu√≠a b√°sica de sintaxis SQL
- üèóÔ∏è **`EJEMPLOS_NORMALIZACION.md`** - Ejemplos de normalizaci√≥n de bases de datos

### **Para Desarrolladores:**
- üê≥ **`COMANDOS_RAPIDOS_DOCKER.md`** - Comandos Docker √∫tiles
- üêß **`COMANDOS_BASICOS_LINUX.md`** - Comandos Linux b√°sicos
- üßπ **`CLEANUP.md`** - Limpieza y mantenimiento del entorno

---

## üîß CONFIGURACI√ìN DE HDFS PARA HIVE

### Contexto T√©cnico
HDFS (Hadoop Distributed File System) requiere la creaci√≥n de directorios espec√≠ficos para el funcionamiento correcto de Apache Hive. Estos directorios deben existir antes de iniciar los servicios de Hive.

### Paso 2.1: Acceso al Contenedor Master
```bash
docker exec -it master bash
```

**Par√°metros del Comando**:
- `exec`: Ejecuta un comando en un contenedor en ejecuci√≥n
- `-i`: Modo interactivo (mantiene STDIN abierto)
- `-t`: Asigna una pseudo-TTY
- `master`: Nombre del contenedor objetivo
- `bash`: Shell a ejecutar

**Indicador de √âxito**: El prompt cambiar√° a `root@master:/opt/hadoop#`

### Paso 2.2: Creaci√≥n de Directorios HDFS
```bash
# Directorio principal del warehouse de Hive
hdfs dfs -mkdir -p /user/hive/warehouse

# Directorio temporal para operaciones
hdfs dfs -mkdir -p /tmp

# Directorio de usuario de Hive
hdfs dfs -mkdir -p /user/hive
```

**Comandos HDFS Utilizados**:
- `hdfs dfs -mkdir -p`: Crea directorios en HDFS con opci√≥n recursiva
- `-p`: Crea directorios padre si no existen

### Paso 2.3: Configuraci√≥n de Permisos HDFS
```bash
# Asignar permisos de lectura, escritura y ejecuci√≥n para todos los usuarios
hdfs dfs -chmod 777 /user/hive/warehouse
hdfs dfs -chmod 777 /tmp
hdfs dfs -chmod 777 /user/hive
```

**Especificaci√≥n de Permisos 777**:
- Primer 7: Propietario (rwx = 4+2+1)
- Segundo 7: Grupo (rwx = 4+2+1)  
- Tercer 7: Otros (rwx = 4+2+1)

**Nota de Seguridad**: Los permisos 777 se utilizan √∫nicamente en entornos de desarrollo.

### Paso 2.4: Verificaci√≥n de Creaci√≥n de Directorios
```bash
# Listar contenido del directorio warehouse
hdfs dfs -ls /user/hive/

# Listar contenido del directorio temporal
hdfs dfs -ls /tmp/
```

**Salida Esperada**: `drwxrwxrwx` seguido de los nombres de directorios, indicando permisos 777.

### Paso 2.5: Terminaci√≥n de Sesi√≥n
```bash
exit
```

---

## üêù CONFIGURACI√ìN DE APACHE HIVE

### Contexto T√©cnico
Apache Hive requiere una configuraci√≥n espec√≠fica del archivo `hive-site.xml` para funcionar correctamente con PostgreSQL como metastore y HDFS como almacenamiento.

### Paso 3.1: Reacceso al Contenedor Master
```bash
docker exec -it master bash
```

### Paso 3.2: Backup de Configuraci√≥n Actual
```bash
# Crear respaldo de la configuraci√≥n existente
cp /opt/hive/conf/hive-site.xml /opt/hive/conf/hive-site.xml.backup
```

**Prop√≥sito**: Mantener una copia de seguridad de la configuraci√≥n original para recuperaci√≥n en caso de fallos.

### Paso 3.3: Aplicaci√≥n de Configuraci√≥n Optimizada
```bash
# Aplicar configuraci√≥n pre-validada
cp /opt/hive/conf/hive-site-working.xml /opt/hive/conf/hive-site.xml
```

**Descripci√≥n T√©cnica**: El archivo `hive-site-working.xml` contiene la configuraci√≥n optimizada que incluye:
- Configuraci√≥n del metastore PostgreSQL
- Par√°metros de HiveServer2
- Configuraci√≥n de HDFS
- Par√°metros de ejecuci√≥n

### Paso 3.4: Reinicio de Servicios de Hive
```bash
# Terminaci√≥n de procesos Hive existentes
pkill -f HiveServer2
pkill -f MetaStore

# Inicializaci√≥n del servicio metastore en background
/opt/hive/bin/hive --service metastore &

# Inicializaci√≥n del servicio HiveServer2 en background
/opt/hive/bin/hive --service hiveserver2 &
```

**Comandos de Proceso**:
- `pkill -f`: Termina procesos bas√°ndose en coincidencia de patrones
- `&`: Ejecuta el comando en background

**Servicios Iniciados**:
- **Metastore**: Gestiona metadatos de tablas y particiones
- **HiveServer2**: Proporciona interfaz JDBC/ODBC para conexiones

### Paso 3.5: Terminaci√≥n de Sesi√≥n
```bash
exit
```

---

## ‚úÖ VERIFICACI√ìN DE FUNCIONALIDAD

### Paso 4.1: Verificaci√≥n de Estado de HiveServer2
```bash
# Verificar que HiveServer2 est√© escuchando en el puerto 10000
docker exec master netstat -tlnp | grep 10000
```

**Salida Esperada**: `tcp 0 0 0.0.0.0:10000 0.0.0.0:* LISTEN`

**Interpretaci√≥n**: El servicio HiveServer2 est√° activo y escuchando conexiones en todas las interfaces del puerto 10000.

### Paso 4.2: Conexi√≥n de Prueba a Hive
```bash
# Establecer conexi√≥n JDBC a Hive mediante beeline
docker exec -it master /opt/hive/bin/beeline -u jdbc:hive2://localhost:10000
```

**Componentes T√©cnicos**:
- **Beeline**: Cliente de l√≠nea de comandos para Hive basado en SQLLine
- **JDBC URL**: `jdbc:hive2://localhost:10000` - Conexi√≥n local al puerto 10000

**Indicadores de Conexi√≥n Exitosa**:
- Mensaje de versi√≥n: `Beeline version 3.1.3 by Apache Hive`
- Prompt de conexi√≥n: `0: jdbc:hive2://localhost:10000>`

### Paso 4.3: Prueba de Funcionalidad
```sql
-- Consulta de verificaci√≥n de bases de datos
SHOW DATABASES;
```

**Prop√≥sito**: Verificar que Hive responda correctamente a consultas SQL b√°sicas.

### Paso 4.4: Terminaci√≥n de Sesi√≥n Beeline
```sql
!quit
```

---

## üåê INTERFACES DE ADMINISTRACI√ìN WEB

### Hadoop Distributed File System (HDFS)
- **NameNode Web UI**: http://localhost:9870 - Administraci√≥n de metadatos HDFS
- **ResourceManager Web UI**: http://localhost:8088 - Gesti√≥n de recursos YARN
- **HistoryServer Web UI**: http://localhost:19888 - Historial de trabajos MapReduce

### Apache Spark
- **Spark Master Web UI**: http://localhost:8080 - Estado del cl√∫ster Spark
- **Worker1 Web UI**: http://localhost:8081 - Estado del worker 1
- **Worker2 Web UI**: http://localhost:8082 - Estado del worker 2
- **Spark History Server**: http://localhost:18080 - Historial de aplicaciones Spark

### Apache Hive
- **JDBC Connection String**: `jdbc:hive2://localhost:10000`
- **Protocolo**: HiveServer2 Thrift

### Jupyter Notebook
- **Web Interface**: http://localhost:8888
- **Kernel Disponible**: PySpark
- **Ejemplo de Notebook**: [jupyter/notebook/pyspark.ipynb](jupyter/notebook/pyspark.ipynb)

---

## üõ†Ô∏è GESTI√ìN OPERATIVA DEL CL√öSTER

### Monitoreo del Estado
```bash
# Estado de todos los contenedores
docker-compose ps

# Logs de todos los servicios
docker-compose logs

# Logs en tiempo real de servicios espec√≠ficos
docker-compose logs -f master
docker-compose logs -f metastore
```

### Control de Servicios
```bash
# Detener todos los servicios
make down

# Iniciar todos los servicios
make up

# Verificar estado del cl√∫ster
make status

# Limpieza de im√°genes Docker
make clean
```

---

## üîç RESOLUCI√ìN DE PROBLEMAS

### Problema: Fallo de Conexi√≥n a Hive
**S√≠ntomas**: Error de conexi√≥n JDBC o timeout en beeline

**Procedimiento de Diagn√≥stico**:
1. **Verificaci√≥n de PostgreSQL**:
   ```bash
   docker-compose logs metastore
   ```

2. **Verificaci√≥n de Directorios HDFS**:
   ```bash
   docker exec master hdfs dfs -ls /user/hive/
   ```

3. **Verificaci√≥n de Configuraci√≥n Hive**:
   ```bash
   docker exec master ls -la /opt/hive/conf/hive-site.xml
   ```

4. **Verificaci√≥n de Estado de HiveServer2**:
   ```bash
   docker exec master netstat -tlnp | grep 10000
   ```

### Problema: HDFS No Accesible
**S√≠ntomas**: Errores de permisos o directorios no encontrados

**Procedimiento de Diagn√≥stico**:
1. **Verificaci√≥n de NameNode**:
   ```bash
   docker-compose logs master
   ```

2. **Verificaci√≥n de DataNodes**:
   - Acceder a http://localhost:9870
   - Verificar que 2 DataNodes est√©n en estado "Active"

### Problema: Spark No Operativo
**S√≠ntomas**: Interfaz web no accesible o workers desconectados

**Procedimiento de Diagn√≥stico**:
1. **Verificaci√≥n de Spark Master**:
   - Acceder a http://localhost:8080
   - Verificar estado del master

2. **Verificaci√≥n de Workers**:
   - En http://localhost:8080 verificar presencia de 2 workers
   - Estado de workers debe ser "ALIVE"

---

## üìö STACK TECNOL√ìGICO

### Componentes Core
- **Apache Hadoop 3.3.6**: Framework de procesamiento distribuido
- **Apache Hive 3.1.3**: Data warehouse para consultas SQL
- **Apache Spark 3.5.3**: Motor de procesamiento de datos en memoria
- **PostgreSQL 11**: Sistema de gesti√≥n de bases de datos relacional
- **Jupyter Notebook**: Entorno de desarrollo interactivo

### Versiones de Componentes
- **Java**: OpenJDK 8
- **Python**: Python 3.8+
- **Scala**: Scala 2.12

---

## üèóÔ∏è ARQUITECTURA DEL CL√öSTER

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Metastore ‚îÇ    ‚îÇ    Master   ‚îÇ    ‚îÇ   Worker1   ‚îÇ
‚îÇ (PostgreSQL)‚îÇ    ‚îÇ (NameNode,  ‚îÇ    ‚îÇ (DataNode,  ‚îÇ
‚îÇ             ‚îÇ    ‚îÇ ResourceMgr)‚îÇ    ‚îÇ  NodeMgr)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                   ‚îÇ                   ‚îÇ
       ‚îÇ                   ‚îÇ                   ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                   ‚îÇ       ‚îÇ       ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇWorker2  ‚îÇ ‚îÇ History ‚îÇ
              ‚îÇ(DataNode‚îÇ ‚îÇ(History ‚îÇ
              ‚îÇ NodeMgr)‚îÇ ‚îÇ Server) ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Descripci√≥n de Componentes
- **Metastore (PostgreSQL)**: Almacena metadatos de tablas, particiones y esquemas de Hive
- **Master Node**: Coordina el cl√∫ster (NameNode + ResourceManager)
- **Worker Nodes**: Procesan datos y almacenan bloques HDFS
- **History Server**: Mantiene historial de trabajos Spark y MapReduce

---

## üöÄ PROCEDIMIENTO DE CONFIGURACI√ìN COMPLETO

### Configuraci√≥n Manual (Recomendado para Entornos de Desarrollo)
```bash
# 1. Despliegue del cl√∫ster
make
docker-compose up -d

# 2. Acceso al contenedor master
docker exec -it master bash

# 3. Configuraci√≥n de HDFS
hdfs dfs -mkdir -p /user/hive/warehouse /tmp /user/hive
hdfs dfs -chmod 777 /user/hive/warehouse /tmp /user/hive

# 4. Configuraci√≥n de Hive
cp /opt/hive/conf/hive-site-working.xml /opt/hive/conf/hive-site.xml

# 5. Reinicio de servicios Hive
pkill -f HiveServer2 && pkill -f MetaStore
/opt/hive/bin/hive --service metastore &
/opt/hive/bin/hive --service hiveserver2 &

# 6. Terminaci√≥n de sesi√≥n
exit

# 7. Verificaci√≥n de funcionalidad
docker exec master netstat -tlnp | grep 10000
```

### Configuraci√≥n Automatizada (Para Entornos de Producci√≥n/Testing)
```bash
# Despliegue y configuraci√≥n completa en una secuencia
make && docker-compose up -d
docker exec master hdfs dfs -mkdir -p /user/hive/warehouse /tmp /user/hive
docker exec master hdfs dfs -chmod 777 /user/hive/warehouse /tmp /user/hive
docker exec master cp /opt/hive/conf/hive-site-working.xml /opt/hive/conf/hive-site.xml
docker exec master bash -c "pkill -f HiveServer2; pkill -f MetaStore; /opt/hive/bin/hive --service metastore & /opt/hive/bin/hive --service hiveserver2 &"
```

---

## üìù CONSIDERACIONES T√âCNICAS

### Configuraci√≥n de Red
- **Subnet**: 172.28.0.0/16
- **IPs Est√°ticas**: Asignadas a cada servicio para comunicaci√≥n interna
- **Port Mapping**: Mapeo de puertos internos a puertos del host

### Persistencia de Datos
- **Vol√∫menes Docker**: Mantienen datos entre reinicios del cl√∫ster
- **HDFS**: Almacenamiento distribuido con replicaci√≥n
- **PostgreSQL**: Metadatos persistentes de Hive

### Configuraci√≥n de Seguridad
- **Autenticaci√≥n**: Configurada como NONE para desarrollo
- **Permisos HDFS**: 777 para facilitar operaciones de desarrollo
- **Red Aislada**: Comunicaci√≥n interna a trav√©s de red Docker personalizada

---

## üéØ OPERACIONES POST-CONFIGURACI√ìN

### Verificaci√≥n de Funcionalidad
1. **HDFS**: Acceder a http://localhost:9870 para explorar el sistema de archivos
2. **Hive**: Conectar via beeline y ejecutar consultas SQL de prueba
3. **Spark**: Verificar estado en http://localhost:8080
4. **Jupyter**: Desarrollar notebooks PySpark en http://localhost:8888

### Monitoreo Continuo
- **Logs de Servicios**: `docker-compose logs -f [servicio]`
- **Estado de Contenedores**: `docker-compose ps`
- **M√©tricas HDFS**: http://localhost:9870
- **M√©tricas YARN**: http://localhost:8088

---

## üÜò SOPORTE T√âCNICO

### Procedimiento de Resoluci√≥n de Problemas
1. **An√°lisis de Logs**: `docker-compose logs -f [servicio_afectado]`
2. **Verificaci√≥n de Estado**: `docker-compose ps`
3. **Documentaci√≥n**: Revisar este README para procedimientos espec√≠ficos
4. **Reinicializaci√≥n**: `make clean && make && docker-compose up -d`

### Recursos de Diagn√≥stico
- **Docker Logs**: Informaci√≥n detallada de servicios
- **Interfaces Web**: Monitoreo en tiempo real
- **Comandos de Verificaci√≥n**: Scripts de diagn√≥stico incluidos

**Nota**: La primera inicializaci√≥n puede requerir tiempo adicional para descarga de im√°genes y configuraci√≥n inicial.