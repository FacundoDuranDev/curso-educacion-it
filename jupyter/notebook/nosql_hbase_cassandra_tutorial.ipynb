{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🗄️ Tutorial Completo: HBase + Cassandra\n",
    "\n",
    "**🎯 Objetivos:**\n",
    "- Conectarse a HBase y realizar operaciones básicas\n",
    "- Conectarse a Cassandra y crear keyspaces/tablas\n",
    "- Realizar operaciones CRUD en ambas bases NoSQL\n",
    "- Integrar con Spark para análisis de datos\n",
    "\n",
    "**🔧 Servicios necesarios:**\n",
    "- HBase: `http://localhost:16010` (Web UI)\n",
    "- Cassandra: Puerto `9042` (CQL)\n",
    "- Spark: Integración con ambas bases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦 Instalación de Drivers Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Instalando drivers NoSQL...\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: happybase in /home/jupyter/.local/lib/python3.10/site-packages (1.2.0)\n",
      "Requirement already satisfied: six in /home/jupyter/.local/lib/python3.10/site-packages (from happybase) (1.17.0)\n",
      "Requirement already satisfied: thriftpy2>=0.4 in /home/jupyter/.local/lib/python3.10/site-packages (from happybase) (0.5.3)\n",
      "Requirement already satisfied: ply<4.0,>=3.4 in /home/jupyter/.local/lib/python3.10/site-packages (from thriftpy2>=0.4->happybase) (3.11)\n",
      "✅ happybase instalado exitosamente\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: cassandra-driver in /home/jupyter/.local/lib/python3.10/site-packages (3.29.2)\n",
      "Requirement already satisfied: geomet<0.3,>=0.1 in /home/jupyter/.local/lib/python3.10/site-packages (from cassandra-driver) (0.2.1.post1)\n",
      "Requirement already satisfied: six in /home/jupyter/.local/lib/python3.10/site-packages (from geomet<0.3,>=0.1->cassandra-driver) (1.17.0)\n",
      "Requirement already satisfied: click in /home/jupyter/.local/lib/python3.10/site-packages (from geomet<0.3,>=0.1->cassandra-driver) (8.3.0)\n",
      "✅ cassandra-driver instalado exitosamente\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: thrift in /home/jupyter/.local/lib/python3.10/site-packages (0.22.0)\n",
      "✅ thrift instalado exitosamente\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/jupyter/.local/lib/python3.10/site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /home/jupyter/.local/lib/python3.10/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jupyter/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jupyter/.local/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jupyter/.local/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/jupyter/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "✅ pandas instalado exitosamente\n",
      "\n",
      "🎉 ¡Instalación completada!\n"
     ]
    }
   ],
   "source": [
    "# Instalar drivers necesarios\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"✅ {package} instalado exitosamente\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error instalando {package}: {e}\")\n",
    "\n",
    "# Drivers necesarios\n",
    "packages = [\n",
    "    \"happybase\",        # HBase Python client\n",
    "    \"cassandra-driver\", # Cassandra Python driver\n",
    "    \"thrift\",          # Dependencia para HBase\n",
    "    \"pandas\",          # Para manipulación de datos\n",
    "]\n",
    "\n",
    "print(\"🔧 Instalando drivers NoSQL...\")\n",
    "for package in packages:\n",
    "    install_package(package)\n",
    "\n",
    "print(\"\\n🎉 ¡Instalación completada!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏛️ PARTE 1: HBase (Columnar NoSQL)\n",
    "\n",
    "**HBase** es una base de datos **columnar** distribuida, ideal para:\n",
    "- Grandes volúmenes de datos\n",
    "- Acceso aleatorio rápido\n",
    "- Esquemas flexibles\n",
    "- Integración con Hadoop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 ¡Conexión a HBase exitosa!\n",
      "📊 Tablas existentes: 2\n",
      "📋 Lista de tablas:\n",
      "   - educacionit_clientes\n",
      "   - test_table\n"
     ]
    }
   ],
   "source": [
    "# 🔗 Conectar a HBase\n",
    "import happybase\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "try:\n",
    "    # Conectar al contenedor HBase\n",
    "    hbase_connection = happybase.Connection(\n",
    "        host='hbase',  # Nombre del servicio en Docker\n",
    "        port=9090,     # Puerto Thrift\n",
    "        timeout=10000\n",
    "    )\n",
    "    \n",
    "    # Test de conexión\n",
    "    tables = list(hbase_connection.tables())\n",
    "    \n",
    "    print(\"🎉 ¡Conexión a HBase exitosa!\")\n",
    "    print(f\"📊 Tablas existentes: {len(tables)}\")\n",
    "    \n",
    "    if tables:\n",
    "        print(\"📋 Lista de tablas:\")\n",
    "        for table in tables:\n",
    "            print(f\"   - {table.decode('utf-8')}\")\n",
    "    else:\n",
    "        print(\"📝 No hay tablas creadas aún\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error conectando a HBase: {e}\")\n",
    "    print(\"🔍 Verificar que el servicio HBase esté ejecutándose\")\n",
    "    hbase_connection = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗑️ Eliminando tabla existente: educacionit_clientes\n",
      "🏗️ Creando tabla: educacionit_clientes\n",
      "✅ Tabla 'educacionit_clientes' creada exitosamente\n",
      "👥 Familias de columnas: ['info', 'contact', 'stats']\n"
     ]
    }
   ],
   "source": [
    "# 🏗️ Crear tabla en HBase\n",
    "if hbase_connection:\n",
    "    try:\n",
    "        table_name = 'educacionit_clientes'\n",
    "        \n",
    "        # Definir familias de columnas\n",
    "        families = {\n",
    "            'info': dict(),      # Información personal\n",
    "            'contact': dict(),   # Información de contacto\n",
    "            'stats': dict()      # Estadísticas\n",
    "        }\n",
    "        \n",
    "        # Eliminar tabla si existe (para demo)\n",
    "        if table_name.encode() in hbase_connection.tables():\n",
    "            print(f\"🗑️ Eliminando tabla existente: {table_name}\")\n",
    "            hbase_connection.delete_table(table_name, disable=True)\n",
    "        \n",
    "        # Crear nueva tabla\n",
    "        print(f\"🏗️ Creando tabla: {table_name}\")\n",
    "        hbase_connection.create_table(table_name, families)\n",
    "        \n",
    "        # Obtener referencia a la tabla\n",
    "        hbase_table = hbase_connection.table(table_name)\n",
    "        \n",
    "        print(f\"✅ Tabla '{table_name}' creada exitosamente\")\n",
    "        print(f\"👥 Familias de columnas: {list(families.keys())}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error creando tabla: {e}\")\n",
    "        hbase_table = None\n",
    "else:\n",
    "    print(\"⚠️ No hay conexión a HBase\")\n",
    "    hbase_table = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Insertando datos de ejemplo...\n",
      "   ✅ Cliente insertado: cliente_001\n",
      "   ✅ Cliente insertado: cliente_002\n",
      "\n",
      "🎉 ¡2 clientes insertados exitosamente!\n"
     ]
    }
   ],
   "source": [
    "# 📝 Insertar datos en HBase\n",
    "if hbase_table:\n",
    "    try:\n",
    "        print(\"📝 Insertando datos de ejemplo...\")\n",
    "        \n",
    "        # Datos de ejemplo\n",
    "        clientes_data = [\n",
    "            {\n",
    "                'row_key': 'cliente_001',\n",
    "                'data': {\n",
    "                    b'info:nombre': b'Juan Perez',\n",
    "                    b'info:edad': b'35',\n",
    "                    b'info:ciudad': b'Buenos Aires',\n",
    "                    b'contact:email': b'juan.perez@email.com',\n",
    "                    b'contact:telefono': b'+54-11-1234-5678',\n",
    "                    b'stats:compras_total': b'15',\n",
    "                    b'stats:monto_total': b'25000.50'\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'row_key': 'cliente_002',\n",
    "                'data': {\n",
    "                    b'info:nombre': b'Maria Garcia',\n",
    "                    b'info:edad': b'28',\n",
    "                    b'info:ciudad': b'Cordoba',\n",
    "                    b'contact:email': b'maria.garcia@email.com',\n",
    "                    b'contact:telefono': b'+54-351-9876-5432',\n",
    "                    b'stats:compras_total': b'8',\n",
    "                    b'stats:monto_total': b'12750.00'\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Insertar cada cliente\n",
    "        for cliente in clientes_data:\n",
    "            hbase_table.put(cliente['row_key'], cliente['data'])\n",
    "            print(f\"   ✅ Cliente insertado: {cliente['row_key']}\")\n",
    "        \n",
    "        print(f\"\\n🎉 ¡{len(clientes_data)} clientes insertados exitosamente!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error insertando datos: {e}\")\n",
    "else:\n",
    "    print(\"⚠️ No hay tabla HBase disponible\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Consultando datos de HBase...\n",
      "\n",
      "1️⃣ Consulta por Row Key específica:\n",
      "   📋 Datos de cliente_001:\n",
      "      contact:email: juan.perez@email.com\n",
      "      contact:telefono: +54-11-1234-5678\n",
      "      info:ciudad: Buenos Aires\n",
      "      info:edad: 35\n",
      "      info:nombre: Juan Perez\n",
      "      stats:compras_total: 15\n",
      "      stats:monto_total: 25000.50\n",
      "\n",
      "==================================================\n",
      "2️⃣ Escaneo completo de la tabla:\n",
      "\n",
      "   👤 Cliente: cliente_001\n",
      "      contact:email: juan.perez@email.com\n",
      "      contact:telefono: +54-11-1234-5678\n",
      "      info:ciudad: Buenos Aires\n",
      "      info:edad: 35\n",
      "      info:nombre: Juan Perez\n",
      "      stats:compras_total: 15\n",
      "      stats:monto_total: 25000.50\n",
      "\n",
      "   👤 Cliente: cliente_002\n",
      "      contact:email: maria.garcia@email.com\n",
      "      contact:telefono: +54-351-9876-5432\n",
      "      info:ciudad: Cordoba\n",
      "      info:edad: 28\n",
      "      info:nombre: Maria Garcia\n",
      "      stats:compras_total: 8\n",
      "      stats:monto_total: 12750.00\n",
      "\n",
      "🎉 Escaneados 2 clientes exitosamente\n"
     ]
    }
   ],
   "source": [
    "# 🔍 Consultar datos en HBase\n",
    "if hbase_table:\n",
    "    try:\n",
    "        print(\"🔍 Consultando datos de HBase...\\n\")\n",
    "        \n",
    "        # 1. Consultar un cliente específico\n",
    "        print(\"1️⃣ Consulta por Row Key específica:\")\n",
    "        cliente_001 = hbase_table.row(b'cliente_001')\n",
    "        \n",
    "        if cliente_001:\n",
    "            print(\"   📋 Datos de cliente_001:\")\n",
    "            for key, value in cliente_001.items():\n",
    "                family_column = key.decode('utf-8')\n",
    "                data_value = value.decode('utf-8')\n",
    "                print(f\"      {family_column}: {data_value}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        \n",
    "        # 2. Escanear toda la tabla\n",
    "        print(\"2️⃣ Escaneo completo de la tabla:\")\n",
    "        \n",
    "        count = 0\n",
    "        for row_key, data in hbase_table.scan():\n",
    "            count += 1\n",
    "            print(f\"\\n   👤 Cliente: {row_key.decode('utf-8')}\")\n",
    "            \n",
    "            # Mostrar datos organizados\n",
    "            for key, value in data.items():\n",
    "                family_column = key.decode('utf-8')\n",
    "                data_value = value.decode('utf-8')\n",
    "                print(f\"      {family_column}: {data_value}\")\n",
    "        \n",
    "        print(f\"\\n🎉 Escaneados {count} clientes exitosamente\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error consultando datos: {e}\")\n",
    "else:\n",
    "    print(\"⚠️ No hay tabla HBase disponible\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌟 PARTE 2: Cassandra (Distribuida NoSQL)\n",
    "\n",
    "**Cassandra** es una base de datos **distribuida** NoSQL, ideal para:\n",
    "- Alta disponibilidad\n",
    "- Escalabilidad horizontal\n",
    "- Tolerancia a fallos\n",
    "- Escrituras masivas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔗 Conectar a Cassandra\n",
    "from cassandra.cluster import Cluster\n",
    "import uuid\n",
    "\n",
    "try:\n",
    "    # Crear cluster de Cassandra\n",
    "    cluster = Cluster(\n",
    "        contact_points=['cassandra'],  # Nombre del servicio en Docker\n",
    "        port=9042\n",
    "    )\n",
    "    \n",
    "    # Crear sesión\n",
    "    cassandra_session = cluster.connect()\n",
    "    \n",
    "    # Test de conexión\n",
    "    result = cassandra_session.execute(\"SELECT release_version FROM system.local\")\n",
    "    version = result.one()[0]\n",
    "    \n",
    "    print(\"🎉 ¡Conexión a Cassandra exitosa!\")\n",
    "    print(f\"🔢 Versión de Cassandra: {version}\")\n",
    "    \n",
    "    # Listar keyspaces existentes\n",
    "    keyspaces = cassandra_session.execute(\"SELECT keyspace_name FROM system_schema.keyspaces\")\n",
    "    \n",
    "    print(\"🗄️ Keyspaces existentes:\")\n",
    "    for keyspace in keyspaces:\n",
    "        print(f\"   - {keyspace[0]}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error conectando a Cassandra: {e}\")\n",
    "    print(\"🔍 Verificar que el servicio Cassandra esté ejecutándose\")\n",
    "    cassandra_session = None\n",
    "    cluster = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🏗️ Crear Keyspace y Tablas en Cassandra\n",
    "if cassandra_session:\n",
    "    try:\n",
    "        keyspace_name = 'educacionit_nosql'\n",
    "        \n",
    "        # Crear keyspace\n",
    "        create_keyspace_cql = f\"\"\"\n",
    "        CREATE KEYSPACE IF NOT EXISTS {keyspace_name}\n",
    "        WITH replication = {{\n",
    "            'class': 'SimpleStrategy',\n",
    "            'replication_factor': 1\n",
    "        }}\n",
    "        \"\"\"\n",
    "        \n",
    "        cassandra_session.execute(create_keyspace_cql)\n",
    "        print(f\"✅ Keyspace '{keyspace_name}' creado/verificado\")\n",
    "        \n",
    "        # Usar el keyspace\n",
    "        cassandra_session.set_keyspace(keyspace_name)\n",
    "        print(f\"🎯 Usando keyspace: {keyspace_name}\")\n",
    "        \n",
    "        # Crear tabla de productos\n",
    "        create_productos_cql = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS productos (\n",
    "            id UUID PRIMARY KEY,\n",
    "            nombre TEXT,\n",
    "            categoria TEXT,\n",
    "            precio DECIMAL,\n",
    "            stock INT,\n",
    "            fecha_creacion TIMESTAMP,\n",
    "            activo BOOLEAN\n",
    "        )\n",
    "        \"\"\"\n",
    "        \n",
    "        cassandra_session.execute(create_productos_cql)\n",
    "        print(\"✅ Tabla 'productos' creada\")\n",
    "        \n",
    "        # Crear tabla de ventas\n",
    "        create_ventas_cql = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS ventas (\n",
    "            fecha_venta DATE,\n",
    "            id_venta UUID,\n",
    "            cliente_id INT,\n",
    "            producto_id UUID,\n",
    "            cantidad INT,\n",
    "            precio_unitario DECIMAL,\n",
    "            total DECIMAL,\n",
    "            PRIMARY KEY (fecha_venta, id_venta)\n",
    "        ) WITH CLUSTERING ORDER BY (id_venta ASC)\n",
    "        \"\"\"\n",
    "        \n",
    "        cassandra_session.execute(create_ventas_cql)\n",
    "        print(\"✅ Tabla 'ventas' creada\")\n",
    "        \n",
    "        print(\"\\n🎉 ¡Keyspace y tablas creados exitosamente!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error creando keyspace/tablas: {e}\")\n",
    "else:\n",
    "    print(\"⚠️ No hay conexión a Cassandra\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Insertando datos de ejemplo en Cassandra...\n",
      "\n",
      "1️⃣ Insertando productos...\n",
      "   ✅ Producto insertado: Laptop Gaming\n",
      "   ✅ Producto insertado: Mouse Inalambrico\n",
      "   ✅ Producto insertado: Teclado Mecanico\n",
      "\n",
      "2️⃣ Insertando ventas...\n",
      "   ✅ Venta insertada: Cliente 1001 - Total $125000.0\n",
      "   ✅ Venta insertada: Cliente 1002 - Total $5001.0\n",
      "   ✅ Venta insertada: Cliente 1003 - Total $8900.0\n",
      "\n",
      "🎉 ¡Datos insertados exitosamente!\n",
      "\n",
      "============================================================\n",
      "🔍 Consultando datos de Cassandra...\n",
      "\n",
      "📦 Productos disponibles:\n",
      "   • Laptop Gaming - $125000 (Stock: 15)\n",
      "   • Laptop Gaming - $125000 (Stock: 15)\n",
      "   • Teclado Mecanico - $8900 (Stock: 25)\n",
      "   • Mouse Inalambrico - $2500.5 (Stock: 50)\n",
      "   • Teclado Mecanico - $8900 (Stock: 25)\n",
      "   • Laptop Gaming - $125000 (Stock: 15)\n",
      "   • Mouse Inalambrico - $2500.5 (Stock: 50)\n",
      "   • Mouse Inalambrico - $2500.5 (Stock: 50)\n",
      "   • Teclado Mecanico - $8900 (Stock: 25)\n",
      "   • Laptop Gaming - $125000 (Stock: 15)\n",
      "   • Mouse Inalambrico - $2500.5 (Stock: 50)\n",
      "   • Mouse Inalambrico - $2500.5 (Stock: 50)\n",
      "   • Mouse Inalambrico - $2500.5 (Stock: 50)\n",
      "   • Mouse Inalambrico - $2500.5 (Stock: 50)\n",
      "   • Teclado Mecanico - $8900 (Stock: 25)\n",
      "   • Teclado Mecanico - $8900 (Stock: 25)\n",
      "   • Mouse Inalambrico - $2500.5 (Stock: 50)\n",
      "   • Laptop Gaming - $125000 (Stock: 15)\n",
      "   • Laptop Gaming - $125000 (Stock: 15)\n",
      "   • Teclado Mecanico - $8900 (Stock: 25)\n",
      "   • Laptop Gaming - $125000 (Stock: 15)\n",
      "   • Mouse Inalambrico - $2500.5 (Stock: 50)\n",
      "   • Laptop Gaming - $125000 (Stock: 15)\n",
      "   • Laptop Gaming - $125000 (Stock: 15)\n",
      "   • Teclado Mecanico - $8900 (Stock: 25)\n",
      "   • Mouse Inalambrico - $2500.5 (Stock: 50)\n",
      "   • Laptop Gaming - $125000 (Stock: 15)\n",
      "   • Mouse Inalambrico - $2500.5 (Stock: 50)\n",
      "   • Teclado Mecanico - $8900 (Stock: 25)\n",
      "   • Laptop Gaming - $125000 (Stock: 15)\n",
      "   • Mouse Inalambrico - $2500.5 (Stock: 50)\n",
      "   • Teclado Mecanico - $8900 (Stock: 25)\n",
      "   • Teclado Mecanico - $8900 (Stock: 25)\n",
      "   • Teclado Mecanico - $8900 (Stock: 25)\n",
      "   • Mouse Inalambrico - $2500.5 (Stock: 50)\n",
      "   • Laptop Gaming - $125000 (Stock: 15)\n",
      "   • Teclado Mecanico - $8900 (Stock: 25)\n",
      "   • Teclado Mecanico - $8900 (Stock: 25)\n",
      "   • Laptop Gaming - $125000 (Stock: 15)\n",
      "\n",
      "💰 Ventas de hoy (2025-09-20):\n",
      "   • Cliente 1003 - Cantidad: 1 - Total: 8900.00 pesos\n",
      "   • Cliente 1002 - Cantidad: 2 - Total: 5001.00 pesos\n",
      "   • Cliente 1003 - Cantidad: 1 - Total: 8900.00 pesos\n",
      "   • Cliente 1003 - Cantidad: 1 - Total: 8900.00 pesos\n",
      "   • Cliente 1002 - Cantidad: 2 - Total: 5001.00 pesos\n",
      "   • Cliente 1003 - Cantidad: 1 - Total: 8900.00 pesos\n",
      "   • Cliente 1001 - Cantidad: 1 - Total: 125000.00 pesos\n",
      "   • Cliente 1001 - Cantidad: 1 - Total: 125000.00 pesos\n",
      "   • Cliente 1003 - Cantidad: 1 - Total: 8900.00 pesos\n",
      "   • Cliente 1002 - Cantidad: 2 - Total: 5001.00 pesos\n",
      "   • Cliente 1001 - Cantidad: 1 - Total: 125000.00 pesos\n",
      "   • Cliente 1001 - Cantidad: 1 - Total: 125000.00 pesos\n",
      "   • Cliente 1001 - Cantidad: 1 - Total: 125000.00 pesos\n",
      "   • Cliente 1003 - Cantidad: 1 - Total: 8900.00 pesos\n",
      "   • Cliente 1003 - Cantidad: 1 - Total: 8900.00 pesos\n",
      "   • Cliente 1002 - Cantidad: 2 - Total: 5001.00 pesos\n",
      "   • Cliente 1002 - Cantidad: 2 - Total: 5001.00 pesos\n",
      "   • Cliente 1001 - Cantidad: 1 - Total: 125000.00 pesos\n",
      "   • Cliente 1002 - Cantidad: 2 - Total: 5001.00 pesos\n",
      "   • Cliente 1003 - Cantidad: 1 - Total: 8900.00 pesos\n",
      "   • Cliente 1002 - Cantidad: 2 - Total: 5001.00 pesos\n",
      "   • Cliente 1002 - Cantidad: 2 - Total: 5001.00 pesos\n",
      "   • Cliente 1001 - Cantidad: 1 - Total: 125000.00 pesos\n",
      "   • Cliente 1003 - Cantidad: 1 - Total: 8900.00 pesos\n",
      "   • Cliente 1002 - Cantidad: 2 - Total: 5001.00 pesos\n",
      "   • Cliente 1002 - Cantidad: 2 - Total: 5001.00 pesos\n",
      "   • Cliente 1001 - Cantidad: 1 - Total: 125000.00 pesos\n",
      "   • Cliente 1001 - Cantidad: 1 - Total: 125000.00 pesos\n",
      "   • Cliente 1002 - Cantidad: 2 - Total: 5001.00 pesos\n",
      "   • Cliente 1001 - Cantidad: 1 - Total: 125000.00 pesos\n",
      "   • Cliente 1002 - Cantidad: 2 - Total: 5001.00 pesos\n",
      "   • Cliente 1003 - Cantidad: 1 - Total: 8900.00 pesos\n",
      "   • Cliente 1002 - Cantidad: 2 - Total: 5001.00 pesos\n",
      "   • Cliente 1001 - Cantidad: 1 - Total: 125000.00 pesos\n",
      "   • Cliente 1003 - Cantidad: 1 - Total: 8900.00 pesos\n",
      "   • Cliente 1001 - Cantidad: 1 - Total: 125000.00 pesos\n",
      "   • Cliente 1003 - Cantidad: 1 - Total: 8900.00 pesos\n",
      "   • Cliente 1003 - Cantidad: 1 - Total: 8900.00 pesos\n",
      "   • Cliente 1001 - Cantidad: 1 - Total: 125000.00 pesos\n",
      "\n",
      "📊 Resumen: 39 ventas - Total: 1805713.00 pesos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/20 11:48:51 WARN DataStreamer: Exception for BP-651295859-172.28.1.2-1757645932520:blk_1073742217_1414\n",
      "java.net.SocketTimeoutException: 70000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.28.1.7:49288 remote=/172.28.1.3:9866]\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:163)\n",
      "\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n",
      "\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n",
      "\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)\n",
      "\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n",
      "\tat java.io.FilterInputStream.read(FilterInputStream.java:83)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:519)\n",
      "\tat org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:213)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor.run(DataStreamer.java:1137)\n",
      "25/09/20 11:48:51 WARN DataStreamer: Error Recovery for BP-651295859-172.28.1.2-1757645932520:blk_1073742217_1414 in pipeline [DatanodeInfoWithStorage[172.28.1.3:9866,DS-1cdb3c08-7102-404c-b8a8-9a06ae8fe14f,DISK], DatanodeInfoWithStorage[172.28.1.4:9866,DS-f7e93429-9bfa-4d1c-9e2c-6a5dfd5308eb,DISK]]: datanode 0(DatanodeInfoWithStorage[172.28.1.3:9866,DS-1cdb3c08-7102-404c-b8a8-9a06ae8fe14f,DISK]) is bad.\n"
     ]
    }
   ],
   "source": [
    "# 📝 Insertar y Consultar datos en Cassandra\n",
    "if cassandra_session:\n",
    "    try:\n",
    "        print(\"📝 Insertando datos de ejemplo en Cassandra...\\n\")\n",
    "        \n",
    "        # Insertar productos\n",
    "        print(\"1️⃣ Insertando productos...\")\n",
    "        from datetime import datetime, date\n",
    "        \n",
    "        productos_data = [\n",
    "            (uuid.uuid4(), 'Laptop Gaming', 'Electronica', 125000.00, 15, datetime.now(), True),\n",
    "            (uuid.uuid4(), 'Mouse Inalambrico', 'Accesorios', 2500.50, 50, datetime.now(), True),\n",
    "            (uuid.uuid4(), 'Teclado Mecanico', 'Accesorios', 8900.00, 25, datetime.now(), True),\n",
    "        ]\n",
    "        \n",
    "        insert_producto_stmt = cassandra_session.prepare(\n",
    "            \"INSERT INTO productos (id, nombre, categoria, precio, stock, fecha_creacion, activo) VALUES (?, ?, ?, ?, ?, ?, ?)\"\n",
    "        )\n",
    "        \n",
    "        producto_ids = []\n",
    "        for producto in productos_data:\n",
    "            producto_ids.append(producto[0])\n",
    "            cassandra_session.execute(insert_producto_stmt, producto)\n",
    "            print(f\"   ✅ Producto insertado: {producto[1]}\")\n",
    "        \n",
    "        # Insertar ventas\n",
    "        print(\"\\n2️⃣ Insertando ventas...\")\n",
    "        \n",
    "        ventas_data = [\n",
    "            (date.today(), uuid.uuid4(), 1001, producto_ids[0], 1, 125000.00, 125000.00),\n",
    "            (date.today(), uuid.uuid4(), 1002, producto_ids[1], 2, 2500.50, 5001.00),\n",
    "            (date.today(), uuid.uuid4(), 1003, producto_ids[2], 1, 8900.00, 8900.00),\n",
    "        ]\n",
    "        \n",
    "        insert_venta_stmt = cassandra_session.prepare(\n",
    "            \"INSERT INTO ventas (fecha_venta, id_venta, cliente_id, producto_id, cantidad, precio_unitario, total) VALUES (?, ?, ?, ?, ?, ?, ?)\"\n",
    "        )\n",
    "        \n",
    "        for venta in ventas_data:\n",
    "            cassandra_session.execute(insert_venta_stmt, venta)\n",
    "            print(f\"   ✅ Venta insertada: Cliente {venta[2]} - Total ${venta[6]}\")\n",
    "        \n",
    "        print(f\"\\n🎉 ¡Datos insertados exitosamente!\")\n",
    "        \n",
    "        # CONSULTAR DATOS\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"🔍 Consultando datos de Cassandra...\\n\")\n",
    "        \n",
    "        # Consultar productos\n",
    "        print(\"📦 Productos disponibles:\")\n",
    "        productos = cassandra_session.execute(\"SELECT * FROM productos\")\n",
    "        for producto in productos:\n",
    "            print(f\"   • {producto.nombre} - ${producto.precio} (Stock: {producto.stock})\")\n",
    "        \n",
    "        # Consultar ventas del día\n",
    "        fecha_hoy = date.today()\n",
    "        print(f\"\\n💰 Ventas de hoy ({fecha_hoy}):\")\n",
    "        ventas_hoy = cassandra_session.execute(\n",
    "            f\"SELECT * FROM ventas WHERE fecha_venta = '{fecha_hoy}'\"\n",
    "        )\n",
    "        \n",
    "        total_ventas = 0\n",
    "        count_ventas = 0\n",
    "        for venta in ventas_hoy:\n",
    "            count_ventas += 1\n",
    "            total_ventas += float(venta.total)\n",
    "            venta_total = float(venta.total)\n",
    "            print(f\"   • Cliente {venta.cliente_id} - Cantidad: {venta.cantidad} - Total: {venta_total:.2f} pesos\")\n",
    "        \n",
    "        print(f\"\\n📊 Resumen: {count_ventas} ventas - Total: {total_ventas:.2f} pesos\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error con datos Cassandra: {e}\")\n",
    "else:\n",
    "    print(\"⚠️ No hay conexión a Cassandra\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔥 PARTE 3: Integración con Spark\n",
    "\n",
    "**Integrar Spark** con NoSQL para análisis masivos de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚀 CONFIGURACIÓN SPARK EXITOSA (Copiada de spark_cluster_final)\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import time\n",
    "\n",
    "print(\"🔄 Deteniendo sesiones Spark existentes...\")\n",
    "try:\n",
    "    spark.stop()\n",
    "    print(\"🛑 Sesión anterior detenida\")\n",
    "    time.sleep(3)\n",
    "except:\n",
    "    print(\"🔍 No había sesión activa\")\n",
    "\n",
    "# CONFIGURACIÓN EXACTA QUE FUNCIONA\n",
    "spark_nosql = SparkSession.builder \\\n",
    "    .appName(\"NoSQL-Integration-Working\") \\\n",
    "    .master(\"spark://master:7077\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.executor.memory\", \"1g\") \\\n",
    "    .config(\"spark.executor.cores\", \"1\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark_nosql.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(\"🎉 ¡Spark configurado para NoSQL con configuración exitosa!\")\n",
    "print(f\"📊 Spark UI: {spark_nosql.sparkContext.uiWebUrl}\")\n",
    "print(f\"🔗 Master: {spark_nosql.sparkContext.master}\")\n",
    "\n",
    "# Test rápido\n",
    "print(\"\\n🧪 Test básico de conectividad:\")\n",
    "test_rdd = spark_nosql.sparkContext.parallelize([1, 2, 3, 4, 5])\n",
    "suma = test_rdd.reduce(lambda a, b: a + b)\n",
    "print(f\"✅ Test exitoso - Suma: {suma}\")\n",
    "\n",
    "# Ejemplo: Crear DataFrame desde datos de Cassandra\n",
    "if 'cassandra_session' in locals() and cassandra_session:\n",
    "    try:\n",
    "        print(\"\\n📊 Creando DataFrame desde Cassandra...\")\n",
    "        \n",
    "        # Obtener datos de productos\n",
    "        productos_rows = cassandra_session.execute(\"SELECT * FROM productos\")\n",
    "        productos_data = []\n",
    "        \n",
    "        for row in productos_rows:\n",
    "            productos_data.append({\n",
    "                'id': str(row.id),\n",
    "                'nombre': row.nombre,\n",
    "                'categoria': row.categoria,\n",
    "                'precio': float(row.precio),\n",
    "                'stock': row.stock,\n",
    "                'activo': row.activo\n",
    "            })\n",
    "        \n",
    "        if productos_data:\n",
    "            # Crear DataFrame\n",
    "            productos_schema = StructType([\n",
    "                StructField(\"id\", StringType(), True),\n",
    "                StructField(\"nombre\", StringType(), True),\n",
    "                StructField(\"categoria\", StringType(), True),\n",
    "                StructField(\"precio\", DoubleType(), True),\n",
    "                StructField(\"stock\", IntegerType(), True),\n",
    "                StructField(\"activo\", BooleanType(), True)\n",
    "            ])\n",
    "            \n",
    "            productos_df = spark_nosql.createDataFrame(productos_data, productos_schema)\n",
    "            productos_df.createOrReplaceTempView(\"productos_spark\")\n",
    "            \n",
    "            print(f\"✅ DataFrame creado: {productos_df.count()} productos\")\n",
    "            \n",
    "            # Análisis con Spark SQL\n",
    "            print(\"\\n📈 Análisis con Spark:\")\n",
    "            categoria_analysis = spark_nosql.sql(\"\"\"\n",
    "                SELECT categoria, \n",
    "                       COUNT(*) as cantidad,\n",
    "                       AVG(precio) as precio_promedio,\n",
    "                       SUM(stock) as stock_total\n",
    "                FROM productos_spark \n",
    "                WHERE activo = true\n",
    "                GROUP BY categoria\n",
    "                ORDER BY precio_promedio DESC\n",
    "            \"\"\")\n",
    "            \n",
    "            categoria_analysis.show()\n",
    "        else:\n",
    "            print(\"⚠️ No hay datos de productos en Cassandra\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error análisis Spark: {e}\")\n",
    "else:\n",
    "    print(\"⚠️ Ejecuta primero las celdas de Cassandra para tener datos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧹 Cerrar todas las conexiones\n",
    "print(\"🧹 Cerrando conexiones...\\n\")\n",
    "\n",
    "# Cerrar conexión HBase\n",
    "if 'hbase_connection' in locals() and hbase_connection:\n",
    "    try:\n",
    "        hbase_connection.close()\n",
    "        print(\"✅ Conexión HBase cerrada\")\n",
    "    except:\n",
    "        print(\"⚠️ Error cerrando HBase\")\n",
    "\n",
    "# Cerrar conexión Cassandra\n",
    "if 'cassandra_session' in locals() and cassandra_session:\n",
    "    try:\n",
    "        cassandra_session.shutdown()\n",
    "        print(\"✅ Sesión Cassandra cerrada\")\n",
    "    except:\n",
    "        print(\"⚠️ Error cerrando Cassandra\")\n",
    "\n",
    "if 'cluster' in locals() and cluster:\n",
    "    try:\n",
    "        cluster.shutdown()\n",
    "        print(\"✅ Cluster Cassandra cerrado\")\n",
    "    except:\n",
    "        print(\"⚠️ Error cerrando cluster Cassandra\")\n",
    "\n",
    "# Cerrar Spark\n",
    "if 'spark_nosql' in locals() and spark_nosql:\n",
    "    try:\n",
    "        spark_nosql.stop()\n",
    "        print(\"✅ Sesión Spark cerrada\")\n",
    "    except:\n",
    "        print(\"⚠️ Error cerrando Spark\")\n",
    "\n",
    "print(\"\\n🎉 ¡Limpieza completada!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📚 Resumen y Comandos Útiles\n",
    "\n",
    "### 🏛️ **HBase - Comandos Clave:**\n",
    "```python\n",
    "# Conectar\n",
    "connection = happybase.Connection(host='hbase', port=9090)\n",
    "\n",
    "# Crear tabla\n",
    "connection.create_table('tabla', {'familia': dict()})\n",
    "\n",
    "# Insertar datos\n",
    "table.put('row_key', {b'familia:columna': b'valor'})\n",
    "\n",
    "# Consultar\n",
    "row = table.row(b'row_key')\n",
    "for key, data in table.scan():\n",
    "    print(key, data)\n",
    "```\n",
    "\n",
    "### 🌟 **Cassandra - Comandos CQL:**\n",
    "```python\n",
    "# Conectar\n",
    "cluster = Cluster(['cassandra'])\n",
    "session = cluster.connect()\n",
    "\n",
    "# Crear keyspace\n",
    "session.execute(\"CREATE KEYSPACE IF NOT EXISTS mi_keyspace WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1}\")\n",
    "\n",
    "# Crear tabla\n",
    "session.execute(\"CREATE TABLE IF NOT EXISTS tabla (id UUID PRIMARY KEY, nombre TEXT)\")\n",
    "\n",
    "# Insertar\n",
    "session.execute(\"INSERT INTO tabla (id, nombre) VALUES (?, ?)\", [uuid.uuid4(), 'valor'])\n",
    "\n",
    "# Consultar\n",
    "rows = session.execute(\"SELECT * FROM tabla\")\n",
    "```\n",
    "\n",
    "### 🔥 **Spark + NoSQL:**\n",
    "```python\n",
    "# Configuración básica\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"NoSQL-Integration\") \\\n",
    "    .master(\"spark://master:7077\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Crear DataFrame desde datos NoSQL\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.createOrReplaceTempView(\"tabla_temporal\")\n",
    "\n",
    "# Análisis con SQL\n",
    "result = spark.sql(\"SELECT * FROM tabla_temporal\")\n",
    "```\n",
    "\n",
    "### 🌐 **URLs de Monitoreo:**\n",
    "- **HBase Master:** http://localhost:16010\n",
    "- **Cassandra:** Puerto 9042 (CQL)\n",
    "- **Spark UI:** http://localhost:4040 (cuando hay aplicaciones activas)\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 **¡Tutorial Completado!**\n",
    "\n",
    "Has aprendido a:\n",
    "- ✅ Conectarte a HBase y realizar operaciones CRUD\n",
    "- ✅ Trabajar con Cassandra (keyspaces, tablas, consultas)\n",
    "- ✅ Integrar ambas bases NoSQL con Spark\n",
    "- ✅ Realizar análisis de datos distribuidos\n",
    "\n",
    "**¡Ahora tienes las herramientas para trabajar con Big Data NoSQL!** 🚀\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🛠️ SOLUCIÓN: Detener sesión problemática y recrear\n",
    "import time\n",
    "\n",
    "print(\"🔄 Deteniendo TODAS las sesiones Spark...\")\n",
    "\n",
    "# Detener sesión actual si existe\n",
    "try:\n",
    "    spark_nosql.stop()\n",
    "    print(\"🛑 Sesión spark_nosql detenida\")\n",
    "    time.sleep(3)\n",
    "except:\n",
    "    print(\"🔍 No había spark_nosql activa\")\n",
    "\n",
    "# Detener cualquier otra sesión\n",
    "try:\n",
    "    spark.stop()\n",
    "    print(\"🛑 Sesión spark detenida\")\n",
    "    time.sleep(3)\n",
    "except:\n",
    "    print(\"🔍 No había spark activa\")\n",
    "\n",
    "print(\"⏳ Esperando liberación de recursos...\")\n",
    "time.sleep(5)\n",
    "\n",
    "# Recrear con configuración optimizada\n",
    "print(\"\\n🚀 Creando nueva sesión Spark optimizada...\")\n",
    "\n",
    "spark_nosql = SparkSession.builder \\\n",
    "    .appName(\"NoSQL-Final-Clean\") \\\n",
    "    .master(\"spark://master:7077\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.executor.memory\", \"800m\") \\\n",
    "    .config(\"spark.executor.cores\", \"1\") \\\n",
    "    .config(\"spark.executor.instances\", \"1\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"false\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark_nosql.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(\"🎉 ¡Nueva sesión Spark creada!\")\n",
    "print(f\"📊 Spark UI: {spark_nosql.sparkContext.uiWebUrl}\")\n",
    "\n",
    "# Test inmediato\n",
    "print(\"\\n🧪 Test de conectividad:\")\n",
    "test_rdd = spark_nosql.sparkContext.parallelize([1, 2, 3, 4, 5])\n",
    "suma = test_rdd.reduce(lambda a, b: a + b)\n",
    "print(f\"✅ Test exitoso - Suma: {suma}\")\n",
    "print(\"🎯 ¡Sesión funcionando correctamente!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎉 CLUSTER LIMPIO - Crear sesión Spark optimizada\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "print(\"🎯 Creando sesión Spark con cluster limpio...\")\n",
    "\n",
    "# Configuración optimizada para cluster con recursos disponibles\n",
    "spark_clean = SparkSession.builder \\\n",
    "    .appName(\"NoSQL-Clean-Session\") \\\n",
    "    .master(\"spark://master:7077\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.executor.memory\", \"1g\") \\\n",
    "    .config(\"spark.executor.cores\", \"1\") \\\n",
    "    .config(\"spark.executor.instances\", \"2\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"false\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark_clean.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "print(\"🎉 ¡Sesión Spark creada exitosamente!\")\n",
    "print(f\"📊 Spark UI: {spark_clean.sparkContext.uiWebUrl}\")\n",
    "print(f\"🔗 Master: {spark_clean.sparkContext.master}\")\n",
    "\n",
    "# Test inmediato\n",
    "print(\"\\n🧪 Test de conectividad:\")\n",
    "test_rdd = spark_clean.sparkContext.parallelize([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 4)\n",
    "suma = test_rdd.reduce(lambda a, b: a + b)\n",
    "particiones = test_rdd.getNumPartitions()\n",
    "\n",
    "print(f\"✅ Test exitoso:\")\n",
    "print(f\"   🔢 Suma: {suma}\")\n",
    "print(f\"   📊 Particiones: {particiones}\")\n",
    "print(f\"   🎯 ¡Cluster funcionando perfectamente!\")\n",
    "\n",
    "# Análisis con datos de Cassandra\n",
    "if 'cassandra_session' in locals() and cassandra_session:\n",
    "    try:\n",
    "        print(\"\\n📊 Análisis NoSQL con Spark + Cassandra:\")\n",
    "        \n",
    "        # Obtener datos de productos\n",
    "        productos_rows = cassandra_session.execute(\"SELECT * FROM productos\")\n",
    "        productos_data = []\n",
    "        \n",
    "        for row in productos_rows:\n",
    "            productos_data.append({\n",
    "                'id': str(row.id),\n",
    "                'nombre': row.nombre,\n",
    "                'categoria': row.categoria,\n",
    "                'precio': float(row.precio),\n",
    "                'stock': row.stock,\n",
    "                'activo': row.activo\n",
    "            })\n",
    "        \n",
    "        if productos_data:\n",
    "            # Crear DataFrame con Spark\n",
    "            productos_schema = StructType([\n",
    "                StructField(\"id\", StringType(), True),\n",
    "                StructField(\"nombre\", StringType(), True),\n",
    "                StructField(\"categoria\", StringType(), True),\n",
    "                StructField(\"precio\", DoubleType(), True),\n",
    "                StructField(\"stock\", IntegerType(), True),\n",
    "                StructField(\"activo\", BooleanType(), True)\n",
    "            ])\n",
    "            \n",
    "            productos_df = spark_clean.createDataFrame(productos_data, productos_schema)\n",
    "            productos_df.createOrReplaceTempView(\"productos_nosql\")\n",
    "            \n",
    "            print(f\"✅ DataFrame creado: {productos_df.count()} productos\")\n",
    "            \n",
    "            # Análisis distribuido con Spark SQL\n",
    "            print(\"\\n📈 Análisis por categoría:\")\n",
    "            resultado = spark_clean.sql(\"\"\"\n",
    "                SELECT categoria,\n",
    "                       COUNT(*) as cantidad_productos,\n",
    "                       ROUND(AVG(precio), 2) as precio_promedio,\n",
    "                       SUM(stock) as stock_total,\n",
    "                       ROUND(SUM(precio * stock), 2) as valor_inventario\n",
    "                FROM productos_nosql \n",
    "                WHERE activo = true\n",
    "                GROUP BY categoria\n",
    "                ORDER BY valor_inventario DESC\n",
    "            \"\"\")\n",
    "            \n",
    "            resultado.show(truncate=False)\n",
    "            \n",
    "            # Top productos más caros\n",
    "            print(\"\\n💰 Top productos más caros:\")\n",
    "            top_productos = spark_clean.sql(\"\"\"\n",
    "                SELECT nombre, categoria, precio, stock\n",
    "                FROM productos_nosql \n",
    "                WHERE activo = true\n",
    "                ORDER BY precio DESC\n",
    "                LIMIT 5\n",
    "            \"\"\")\n",
    "            \n",
    "            top_productos.show(truncate=False)\n",
    "            \n",
    "        else:\n",
    "            print(\"⚠️ No hay datos de productos en Cassandra\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error en análisis: {e}\")\n",
    "else:\n",
    "    print(\"⚠️ Ejecuta primero las celdas de Cassandra para tener datos\")\n",
    "\n",
    "print(\"\\n🎉 ¡Análisis NoSQL completado exitosamente!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📋 **ORDEN DE EJECUCIÓN CORRECTO**\n",
    "\n",
    "Para que el tutorial funcione completamente, ejecuta las celdas en este orden:\n",
    "\n",
    "### 🔄 **Secuencia Recomendada:**\n",
    "\n",
    "1. **Celda 2:** 📦 Instalar drivers Python (`happybase`, `cassandra-driver`)\n",
    "2. **Celda 4:** 🏛️ Conectar a HBase \n",
    "3. **Celda 5:** 🏗️ Crear tabla en HBase\n",
    "4. **Celda 6:** 📝 Insertar datos en HBase\n",
    "5. **Celda 7:** 🔍 Consultar datos en HBase\n",
    "6. **Celda 9:** 🌟 Conectar a Cassandra\n",
    "7. **Celda 10:** 🏗️ Crear Keyspace y Tablas en Cassandra\n",
    "8. **Celda 11:** 📝 Insertar y Consultar datos en Cassandra ⭐ **IMPORTANTE**\n",
    "9. **Celda 17:** 🎉 Análisis con Spark (requiere datos de Cassandra)\n",
    "10. **Celda 14:** 🧹 Cerrar conexiones\n",
    "\n",
    "### ⚠️ **Nota Importante:**\n",
    "- La **Celda 17** (Spark + Cassandra) requiere que hayas ejecutado la **Celda 11** primero\n",
    "- Si no hay datos en Cassandra, verás el mensaje: \"⚠️ Ejecuta primero las celdas de Cassandra\"\n",
    "\n",
    "### 🎯 **Ejecuta ahora:**\n",
    "1. **Celda 11** (si no lo has hecho)\n",
    "2. **Celda 17** (análisis con Spark)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
